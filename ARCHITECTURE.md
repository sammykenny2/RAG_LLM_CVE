# System Architecture Overview

## Project Purpose
RAG-based CVE validation system that reduces LLM hallucinations in Security Operations Centers (SOCs) by combining retrieval-augmented generation with official CVE metadata to verify threat intelligence reports.

## Data Sources & Preprocessing

### Reference Knowledge Base
- **Input**: Curated threat intelligence PDFs (e.g., `CVEpdf2024.pdf`)
- **Tool**: `localEmbedding4.py`
- **Process**:
  1. Extract text from PDF using PyMuPDF (`fitz`)
  2. Tokenize with spaCy's sentencizer into 10-sentence chunks
  3. Generate embeddings using `all-mpnet-base-v2` SentenceTransformer (768 dimensions)
  4. Save to CSV (e.g., `test6.csv`) with columns: `sentence_chunk`, `embedding`
- **Purpose**: Creates retrieval corpus for contextual grounding and CVE recommendations

### Official CVE Metadata
- **Source**: MITRE/NVD JSON feeds in `../cvelist/2024` (v5 schema)
- **Structure**: Files organized as `<year>/<prefix-xxx>/CVE-<year>-<id>.json`
  - v5 schema: `cveMetadata.cveId`, `containers.cna.affected`, `containers.cna.descriptions`
- **Optional Tools**: `extractCVE4.py` flattens JSONs to `CVEDescription2024.txt` (for human reference only, not used by RAG)

## Runtime Architecture

### Main Implementation: theRag.py

**Design Goals**: Memory-optimized for systems with limited VRAM
**Key Features**:
- Processes only first 10 pages of PDF
- Limits text to 1000-2000 characters
- Uses `torch.float16` precision + `low_cpu_mem_usage=True`
- Wraps all generation in `torch.no_grad()`
- Reads only 1000 rows from embedding CSV
- Returns top-3 retrieval results
- Token generation: 64-256 tokens
- CUDNN deterministic mode for stability

### Execution Flow

1. **Initialization**
   - Load Llama 3.2-1B-Instruct (FP16)
   - Initialize tokenizer with chat template support
   - Set memory optimization flags (CUDNN deterministic mode)

2. **PDF Ingestion**
   - User provides PDF filename
   - Extract text page-by-page (10 pages max)
   - Periodic memory cleanup every 5 pages

3. **CVE Extraction**
   - **Current Implementation**: Send truncated text to Llama → extract CVEs from LLM output with regex `CVE-\d{4}-\d{4,7}`
   - **Known Optimization Opportunity**: Could skip LLM and directly regex the PDF text

4. **CVE Metadata Lookup**
   For each extracted CVE:
   - Parse CVE format: `CVE-<year>-<id>` → extract year and ID
   - Format path: `<id>` → `Nxxx` (e.g., `1234` → `1xxx`, `12345` → `12xxx`)
   - Search: `../cvelist/<year>/<prefix>/CVE-<year>-<id>.json`
   - Extract: `cveId`, `vendor`, `product`, `description`
   - Build concatenated string of all found CVEs

5. **Fallback for Missing CVEs**
   When JSON file not found:
   - Extract 500-char context from report mentioning the CVE
   - Ask Llama (64 tokens) to paraphrase CVE usage in 2 sentences
   - Call `asking_llama_for_advice()` to recommend similar CVE from knowledge base

6. **Interactive Analysis Menu**
   Loop until user exits:
   - **Option 1 - Summarize**: LLM generates report summary (256 tokens)
   - **Option 2 - Validate CVEs**: Compares report usage vs. official descriptions + displays recommendations
   - **Option 3 - Q&A**: Answer custom questions about the report (256 tokens)
   - **Option 4 - Exit**: Cleanup and terminate

### Key Components

#### `asking_llama_for_advice(cveDesp: str) -> str`
**Purpose**: Recommend similar CVE when original not found
**Process**:
1. Load embedding CSV (1000 rows max)
2. Parse string-formatted embeddings to numpy arrays
3. Convert to torch tensor (float32 for consistency)
4. Initialize SentenceTransformer `all-mpnet-base-v2` (**optimization opportunity**: should be global)
5. Call `retrieve_context()` to get top-3 chunks
6. Format retrieved chunks as context string
7. Ask Llama to recommend CVE based on description + context (128 tokens)
8. Cleanup: delete embeddings, run `torch.cuda.empty_cache()` + `gc.collect()`

#### `retrieve_context(query, embeddings, model, n_resources_to_return=3)`
**Purpose**: Semantic search over knowledge base
**Process**:
1. Encode query with SentenceTransformer
2. Ensure dtype consistency between query and corpus embeddings
3. Calculate dot product similarity scores
4. Return indices of top-3 chunks

## Memory Management Strategy

- `torch.backends.cudnn.benchmark = False` (disable auto-tuner)
- `torch.backends.cudnn.deterministic = True` (reproducible but slower)
- Periodic `gc.collect()` during PDF processing
- `torch.no_grad()` context for all generation
- Manual cleanup after each CVE fallback
- Manual cleanup after each menu operation
- Final `cleanup_model()` on exit

## Critical Dependencies

1. **test6.csv**: Must exist before running `theRag.py`; generated by `localEmbedding4.py`
2. **CVE JSON Feeds**: External directory `../cvelist/` must be synced
3. **Hugging Face Access**: Llama model requires approval + `huggingface-cli login`
4. **CUDA**: Optional but strongly recommended for performance

## Design Constraints & Trade-offs

### Current Limitations
1. **CVE Extraction Inefficiency**: Uses LLM for task solvable by regex (wastes tokens and memory)
2. **Embedding Model Reload**: `asking_llama_for_advice()` reloads SentenceTransformer every call
3. **Limited Context Window**: 1000-2000 char limit may miss CVEs in longer reports
4. **No Chunk Size Validation**: Assumes embedding CSV chunks fit in memory without checking

### Architectural Trade-offs
- Prioritizes stability/speed over completeness (acceptable for summaries, may miss details in long reports)
- CVEs processed sequentially (could parallelize but increases memory pressure)
- Retrieval corpus is static (no online updates from NVD/MITRE during runtime)
- 10-page limit balances memory usage vs. coverage

## File Interaction Map

```
User PDF → theRag.py
             ↓
       PyMuPDF (fitz)
             ↓
       Extract Text → CVE Regex
             ↓
    For each CVE → ../cvelist/<year>/<prefix>/CVE-*.json
                           ↓ (if not found)
                     Llama paraphrase → asking_llama_for_advice()
                                                   ↓
                                             test6.csv (embeddings)
                                                   ↓
                                           SentenceTransformer
                                                   ↓
                                           Llama recommendation

Menu Options → Llama (with official CVE descriptions + retrieval context) → User
```

## Security Considerations
- This is a **defensive security tool** for validating CVE usage in reports
- Does not discover, harvest, or exploit vulnerabilities
- Relies on publicly available CVE metadata from MITRE/NVD
- LLM outputs should be human-verified (hallucinations still possible despite RAG)

## Future Optimization Targets
1. Skip LLM for CVE extraction (use direct regex on PDF text)
2. Initialize SentenceTransformer once at startup (global variable)
3. Add input validation for CSV file existence and format
4. Parallelize CVE lookups (if memory permits)
5. Add configurable parameters (page limits, token limits, retrieval top-k)
6. Fix typos in LLM prompts ("recomend" → "recommend", "closly" → "closely")
