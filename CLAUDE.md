# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Git Policy

**CRITICAL: Never commit or push code changes to the git repository unless explicitly requested by the user.**

## Project Overview

RAG-based CVE validation system for security operations centers (SOCs). Validates CVE usage in threat intelligence reports using Meta's Llama 3.2-1B-Instruct model combined with retrieval-augmented generation to reduce LLM hallucinations.

## Prerequisites

- Python 3.10
- CUDA-capable GPU recommended (CPU fallback available)
- Hugging Face account with Llama model access approval
- Run `huggingface-cli login` before first use
- External CVE JSON feeds in `../cvelist/2024` (v4 schema) and `../cvelistV5/cves/2024` (v5 schema)

## Installation

```bash
pip install -r requirements.txt
```

## Workflow

### 1. Build Embedding Database
Run `localEmbedding4.py` to create the retrieval corpus from curated analyst reports:
```bash
python localEmbedding4.py
```
- Prompts for input PDF path (e.g., `CVEpdf2024.pdf`)
- Tokenizes with spaCy sentencizer into 10-sentence chunks
- Encodes with `all-mpnet-base-v2` SentenceTransformer
- Outputs CSV (e.g., `test6.csv`) containing embeddings + text chunks
- **Critical**: `theRag.py` requires this CSV for retrieval context

### 2. (Optional) Generate Human-Readable CVE Reference
Convert MITRE/NVD JSON feeds to flat text for manual browsing:
```bash
python extractCVE4.py  # For v4 schema in ../cvelist/2024
```
- Creates `CVEDescription2024.txt`
- Does **not** affect RAG retrieval; purely for reference

### 3. Run CVE Validation
Main RAG application:
```bash
python theRag.py
```
- Processes only first 10 pages of PDF with periodic memory cleanup
- Limits text length to 1000-2000 characters
- Uses `torch.no_grad()` for all generation operations
- Reads only first 1000 rows from embedding CSV
- Returns top-3 retrieval results
- Token generation limited to 64-256 tokens
- Interactive menu:
  1. Summarize report
  2. Validate CVE usage (compares report context vs. official descriptions + retrieved evidence)
  3. Custom Q&A about report
  4. Exit

## Architecture Details

### CVE Lookup Strategy
1. **JSON File Lookup**: Direct read from `../cvelist/<year>/<4-digit-xxx or 2-digit-xxx>/CVE-<year>-<id>.json`
   - Extracts `cveId`, `vendor`, `product`, `description` from v5 schema
2. **Fallback for Missing CVEs**: If no JSON found:
   - Asks Llama to paraphrase usage in 2 sentences (limited to 500 chars context)
   - Retrieves similar CVEs from `test6.csv` using `asking_llama_for_advice`
   - Generates recommendation for closest matching CVE

### Embedding & Retrieval (`asking_llama_for_advice`)
- Loads `test6.csv` with precomputed `all-mpnet-base-v2` embeddings
- Encodes query (CVE description) with same model
- Returns top-3 chunks via dot product scoring (`sentence_transformers.util.dot_score`)
- Feeds retrieved context + query to Llama for CVE recommendation

### Processing Strategy
- Direct text truncation to fixed character limits (1000-2000 chars)
- All LLM calls wrapped in `torch.no_grad()`
- Aggressive memory cleanup with `torch.cuda.empty_cache()` and `gc.collect()`
- Only reads first 1000 CSV rows for embeddings

## File Paths & Dependencies

### Expected Directory Structure
```
RAG_LLM_CVE/
├── theRag.py
├── localEmbedding4.py
├── test6.csv           # Generated by localEmbedding4.py
└── <your-report>.pdf
../
├── cvelist/
│   └── 2024/           # v4 CVE JSON feeds
└── cvelistV5/
    └── cves/
        └── 2024/       # v5 CVE JSON feeds (primary)
```

### Key File Interactions
- `theRag.py` reads from:
  - User-provided PDF (via `fitz.open`)
  - `test6.csv` (embedding database)
  - `../cvelistV5/cves/<year>/<prefix>/CVE-*.json` (metadata lookup)
- `localEmbedding4.py` writes to:
  - User-specified CSV output path

## Model Configuration

### Llama 3.2-1B-Instruct Settings
- Device: Auto-mapped to CUDA if available
- Model initialization: `torch_dtype=torch.float16`, `low_cpu_mem_usage=True`
- Generation params:
  - `temperature=0.3`
  - `top_p=0.9`
  - `do_sample=True`
- Token limits: 64-256 tokens
- Memory management:
  - `cleanup_model()` helper deletes model + runs `torch.cuda.empty_cache()` and `gc.collect()`
  - CUDNN optimizations: `torch.backends.cudnn.benchmark = False`, `torch.backends.cudnn.deterministic = True`

### Embedding Model
- `all-mpnet-base-v2` from SentenceTransformers
- 768-dimensional embeddings
- Used consistently for both corpus building and query encoding

## Important Notes

- **Sync CVE Feeds**: Ensure `../cvelist/` is up-to-date to minimize "Could Not Find" fallbacks
- **CSV Dependency**: `test6.csv` must exist before running `theRag.py`; without it, retrieval context is unavailable
- **CVE Path Format**: Second set of CVE ID formatted as `Nxxx` (e.g., `4` → `0xxx`, `12345` → `12xxx`) via `format_second_set()`
