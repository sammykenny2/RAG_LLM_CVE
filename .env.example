# =============================================================================
# RAG_LLM_CVE Configuration Template
# =============================================================================
# Copy this file to .env and modify the values according to your environment
# Command: cp .env.example .env (Linux/Mac) or copy .env.example .env (Windows)
# Note: .env is gitignored and will not be committed to version control

# =============================================================================
# Paths Configuration
# =============================================================================

# Embedding base path (without extension)
# All embedding formats (csv, pkl, parquet, chroma) use this base path
# Default: ./embeddings/CVEEmbeddings (prebuilt, tracked by git)
# For development: ./CVEEmbeddings (working directory, not tracked)
EMBEDDING_PATH=./embeddings/CVEEmbeddings

# CVE JSON feed paths (V5 and V4 schemas)
CVE_V5_PATH=../cvelistV5/cves
CVE_V4_PATH=../cvelist

# Temporary directory for uploaded files (web UI)
TEMP_UPLOAD_DIR=./temp_uploads

# =============================================================================
# Model Configuration
# =============================================================================

# Llama model name (from Hugging Face)
LLAMA_MODEL_NAME=meta-llama/Llama-3.2-1B-Instruct

# Embedding model name (from Hugging Face)
EMBEDDING_MODEL_NAME=sentence-transformers/all-mpnet-base-v2

# Model cache directory (optional, defaults to ~/.cache/huggingface)
# HF_HOME=./models_cache

# =============================================================================
# Default Parameters
# =============================================================================

# Speed level: normal, fast, fastest
DEFAULT_SPEED=fast

# Mode: demo, full
DEFAULT_MODE=full

# Schema: v5, v4, all
DEFAULT_SCHEMA=all

# Embedding format: csv, pkl, parquet, chroma
# Note: Used by localEmbedding.py, theRag.py, and addToEmbeddings.py
# - chroma: Vector database (recommended, optimized queries)
# - pkl: Pickle format (balanced size/speed)
# - parquet: Smallest file, fastest read (requires pyarrow)
# - csv: Text format (largest, slowest, max compatibility)
DEFAULT_EMBEDDING_FORMAT=chroma

# Embedding precision: float32, float16
# Recommendation: float16 for all operations (consistency across tools)
# Note: Used by localEmbedding.py and addToEmbeddings.py
EMBEDDING_PRECISION=float16

# =============================================================================
# RAG Configuration
# =============================================================================

# Conversation history length (number of rounds)
CONVERSATION_HISTORY_LENGTH=10

# Top-K retrieval (number of similar chunks to retrieve)
RETRIEVAL_TOP_K=5

# Chunk size for PDF processing (number of sentences)
CHUNK_SIZE=10

# Chunk overlap for context continuity
CHUNK_OVERLAP=200

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=64

# =============================================================================
# Web UI Configuration
# =============================================================================

# Gradio server port
GRADIO_SERVER_PORT=7860

# Share link (set to True to generate public gradio.live link)
GRADIO_SHARE=False

# Server name (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
GRADIO_SERVER_NAME=127.0.0.1

# Maximum file upload size in MB
MAX_FILE_UPLOAD_SIZE_MB=50

# =============================================================================
# Advanced Configuration
# =============================================================================

# Enable verbose logging (True/False)
VERBOSE_LOGGING=False

# CUDA device index (0 for first GPU, -1 for CPU)
# Leave empty for auto-detection
CUDA_DEVICE=

# Maximum embedding rows to load (None for all, useful for testing)
MAX_EMBEDDING_ROWS=

# Temperature for LLM generation
LLM_TEMPERATURE=0.3

# Top-p for LLM generation
LLM_TOP_P=0.9
